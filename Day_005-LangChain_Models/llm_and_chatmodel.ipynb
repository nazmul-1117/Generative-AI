{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LLM and Chatbot Implementation using HuggingFace"
      ],
      "metadata": {
        "id": "2ddyJtYN1x3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "5hfHUBjM13z7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_gjh3LM01sQ-",
        "outputId": "00c1ff22-d654-449d-89c0-89db248c2fe1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.1.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import langchain\n",
        "langchain.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline"
      ],
      "metadata": {
        "id": "cuKXtyuq2ByW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Access HF Token"
      ],
      "metadata": {
        "id": "5c5b1XqdAs5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Retrieve the token from Colab Secrets\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "# Log in to Hugging Face Hub if the token is available\n",
        "if hf_token:\n",
        "    login(token=hf_token)\n",
        "    print(\"Successfully logged in to Hugging Face!\")\n",
        "else:\n",
        "    print(\"Hugging Face token not found in Colab Secrets. Please add it.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySf5gTdHA-JB",
        "outputId": "c3ff5c00-dfe3-49ad-fd46-7bfe23e191f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully logged in to Hugging Face!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load `LLM Model`"
      ],
      "metadata": {
        "id": "ScVavu1z7YQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model = HuggingFacePipeline.from_model_id(\n",
        "    model_id = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
        "    task = 'text-generation',\n",
        "    pipeline_kwargs = {\n",
        "        \"temperature\": 0.4,\n",
        "        \"max_new_tokens\": 20\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "-f-w1FjWDApq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm_model.invoke(\"What is the Capital of Bangladesh? \")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcoOtdzHEbv7",
        "outputId": "91d620fe-1820-41b6-8ed0-434d1736e40f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.4` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the Capital of Bangladesh? \n",
            "\n",
            "The capital of Bangladesh is Dhaka.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load `Chat Model`"
      ],
      "metadata": {
        "id": "0rfJBCcsFlC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model = ChatHuggingFace(llm = llm_model)"
      ],
      "metadata": {
        "id": "NCy-jjY-FUQO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model_result = chat_model.invoke(\"What is the Capital of Bangladesh?\")\n",
        "print(chat_model_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APOeaD5sF5wd",
        "outputId": "9e3d544b-d930-4fe9-c245-54b2e151b4a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.4` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='<|user|>\\nWhat is the Capital of Bangladesh?</s>\\n<|assistant|>\\nThe capital of Bangladesh is Dhaka.' additional_kwargs={} response_metadata={} id='lc_run--755c9eb0-b7b0-48e7-b494-f3ae5d4ec111-0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model_result.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hwPdiE6oGJob",
        "outputId": "4283642d-7816-4c74-e454-6eebd90cb92e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|user|>\\nWhat is the Capital of Bangladesh?</s>\\n<|assistant|>\\nThe capital of Bangladesh is Dhaka.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "csvdJ4JfGRFG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}