{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOYd61MT6MyAc5LL4xvycvf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d88cd50915e646e6bfa61c3f19b9f2ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5b9b747793b4865bdf6ff08d72b2a3f","IPY_MODEL_a88d1762912146de9c5763789abe1115","IPY_MODEL_782ba7edffb9462a8a0f2d1a28c484da"],"layout":"IPY_MODEL_fef3ce7399d8411b87c4301f46698239"}},"b5b9b747793b4865bdf6ff08d72b2a3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c58c4179f0b4ea3af8e0cd85051b2b2","placeholder":"â€‹","style":"IPY_MODEL_f847e93732ae4fdca6968850844460b4","value":"model.safetensors:â€‡100%"}},"a88d1762912146de9c5763789abe1115":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_021c60b8b2cc4b73a496e357b1144a4f","max":1999811208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1aa549a5bc8a4065b5e795706d6d419e","value":1999811208}},"782ba7edffb9462a8a0f2d1a28c484da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_348aae54b6c34ded9a6e561f6a9b0ca3","placeholder":"â€‹","style":"IPY_MODEL_05dbc586949c4496aa43acdbcd42064c","value":"â€‡2.00G/2.00Gâ€‡[00:40&lt;00:00,â€‡44.5MB/s]"}},"fef3ce7399d8411b87c4301f46698239":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c58c4179f0b4ea3af8e0cd85051b2b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f847e93732ae4fdca6968850844460b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"021c60b8b2cc4b73a496e357b1144a4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1aa549a5bc8a4065b5e795706d6d419e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"348aae54b6c34ded9a6e561f6a9b0ca3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05dbc586949c4496aa43acdbcd42064c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51761fbcf8f546a7a96a6e5722d84b94":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c713a3f949f64c0cac33f64435b5fce1","IPY_MODEL_96e20ca901ac47afbdac307d52a2814a","IPY_MODEL_875026b344ad46408d7f466cbeb75c93"],"layout":"IPY_MODEL_fd8ba4d783cd4890adc1094b50ae7aee"}},"c713a3f949f64c0cac33f64435b5fce1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84df809a3d08493196b933106bba0e9f","placeholder":"â€‹","style":"IPY_MODEL_6ab267f34e15476487ce897f9418e5de","value":"generation_config.json:â€‡100%"}},"96e20ca901ac47afbdac307d52a2814a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3da0ec3114c3467eb0da45f9319e2c86","max":233,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e266ae1bcb1348c08943ff305f5194fd","value":233}},"875026b344ad46408d7f466cbeb75c93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a64a115f53c4326aaf652648ce42e9a","placeholder":"â€‹","style":"IPY_MODEL_d5340cfb242a4d20a3c0a97abd7ae4ba","value":"â€‡233/233â€‡[00:00&lt;00:00,â€‡5.06kB/s]"}},"fd8ba4d783cd4890adc1094b50ae7aee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84df809a3d08493196b933106bba0e9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ab267f34e15476487ce897f9418e5de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3da0ec3114c3467eb0da45f9319e2c86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e266ae1bcb1348c08943ff305f5194fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a64a115f53c4326aaf652648ce42e9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5340cfb242a4d20a3c0a97abd7ae4ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["#Basic of Chains in LangChain"],"metadata":{"id":"sk9fgcrA4i54"}},{"cell_type":"markdown","source":["# Install Libraries"],"metadata":{"id":"T63fAocy4lDf"}},{"cell_type":"code","source":["!pip install --upgrade transformers accelerate langchain-huggingface\n","!pip install -U bitsandbytes"],"metadata":{"id":"BTJxQ7S14kyw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import Libraries"],"metadata":{"id":"xag6dtxt4nUX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1j2NmQKyhcs"},"outputs":[],"source":["import torch"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig"],"metadata":{"id":"GYq-AkCfGI9R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline"],"metadata":{"id":"56Dvd0JHGNkd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser, JsonOutputParser, PydanticOutputParser"],"metadata":{"id":"AnNm3NegIUAq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.messages import HumanMessage, AIMessage, SystemMessage"],"metadata":{"id":"zRD-VK05ovim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.runnables import RunnableParallel, RunnableBranch, RunnableLambda"],"metadata":{"id":"E2RY08r3hSvE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pydantic import BaseModel, Field\n","from typing import Literal"],"metadata":{"id":"Z6PJGH7rm7qz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import Model"],"metadata":{"id":"PM2lRjxJ4pPf"}},{"cell_type":"markdown","source":["## Download Model"],"metadata":{"id":"SDJXjNLN4rkW"}},{"cell_type":"code","source":["quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    bnb_4bit_quant_type=\"nf4\"\n",")"],"metadata":{"id":"UdupjOutZsbB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_id = \"unsloth/gemma-3-1b-it\"\n","# model_id = \"Qwen/Qwen3-4B-Instruct-2507\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","raw_model_llm = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    dtype=torch.float16 if torch.cuda.is_available() else 'auto',\n","    device_map=\"auto\" ,\n","    offload_folder=\"offload\",\n","    offload_state_dict=True,\n","    quantization_config = None\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["d88cd50915e646e6bfa61c3f19b9f2ba","b5b9b747793b4865bdf6ff08d72b2a3f","a88d1762912146de9c5763789abe1115","782ba7edffb9462a8a0f2d1a28c484da","fef3ce7399d8411b87c4301f46698239","6c58c4179f0b4ea3af8e0cd85051b2b2","f847e93732ae4fdca6968850844460b4","021c60b8b2cc4b73a496e357b1144a4f","1aa549a5bc8a4065b5e795706d6d419e","348aae54b6c34ded9a6e561f6a9b0ca3","05dbc586949c4496aa43acdbcd42064c","51761fbcf8f546a7a96a6e5722d84b94","c713a3f949f64c0cac33f64435b5fce1","96e20ca901ac47afbdac307d52a2814a","875026b344ad46408d7f466cbeb75c93","fd8ba4d783cd4890adc1094b50ae7aee","84df809a3d08493196b933106bba0e9f","6ab267f34e15476487ce897f9418e5de","3da0ec3114c3467eb0da45f9319e2c86","e266ae1bcb1348c08943ff305f5194fd","4a64a115f53c4326aaf652648ce42e9a","d5340cfb242a4d20a3c0a97abd7ae4ba"]},"id":"JMgVu_Sg4rHj","executionInfo":{"status":"ok","timestamp":1765507098234,"user_tz":-360,"elapsed":49097,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"df4cf8e4-26fa-4d1a-bbd8-0f6c648a6d4d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d88cd50915e646e6bfa61c3f19b9f2ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/233 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51761fbcf8f546a7a96a6e5722d84b94"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Make Pipeline"],"metadata":{"id":"sUjpUnDB4uQv"}},{"cell_type":"code","source":["pipe = pipeline(\n","    \"text-generation\",\n","    model=raw_model_llm,\n","    tokenizer=tokenizer,\n","    max_new_tokens=200,\n","    temperature=0.0\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_E4oPypV4t_J","executionInfo":{"status":"ok","timestamp":1765507126779,"user_tz":-360,"elapsed":6,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"5f719ce7-5961-4620-84cb-115ba481273b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n"]}]},{"cell_type":"code","source":["llm = HuggingFacePipeline(\n","    pipeline=pipe,\n","    model_kwargs={\n","        \"max_new_tokens\": 200,\n","        \"temperature\": 0.0\n","    }\n",")"],"metadata":{"id":"wcDSkPcdHiC8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Make ChatModel"],"metadata":{"id":"iMl4YZhb40_3"}},{"cell_type":"code","source":["model = ChatHuggingFace(llm=llm)"],"metadata":{"id":"Wr_8R1de4t6O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm.invoke('What is the capital city of bangladesh')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"uO_iS0XD4t2w","executionInfo":{"status":"ok","timestamp":1765507163118,"user_tz":-360,"elapsed":18319,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"f276ca03-7567-40e7-a38e-90dc64031f32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"execute_result","data":{"text/plain":["'What is the capital city of bangladesh?\\n\\nThe capital city of Bangladesh is Dhaka.\\n\\nFinal Answer: The final answer is $\\\\boxed{Dhaka}$'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["model.invoke('What is the capital city of bangladesh')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KcM6aFFsIAHC","executionInfo":{"status":"ok","timestamp":1765507170072,"user_tz":-360,"elapsed":6956,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"d16a1bf1-06f5-4154-e253-b24700c675b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='<bos><start_of_turn>user\\nWhat is the capital city of bangladesh<end_of_turn>\\n<start_of_turn>model\\nThe capital city of Bangladesh is **Dhaka**.\\n', additional_kwargs={}, response_metadata={}, id='lc_run--019b106d-64e8-78a1-a8fb-ba5d410fb275-0')"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["## Chat Prompt Template"],"metadata":{"id":"PxJxod6lIkdy"}},{"cell_type":"code","source":["gemma_template = \"\"\"\n","<start_of_turn>user\n","{input}\n","<end_of_turn>\n","<start_of_turn>model\n","\"\"\"\n","\n","template_prompt = ChatPromptTemplate.from_template(gemma_template)\n","chain = template_prompt | model"],"metadata":{"id":"7BbFqIL6IOzq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chain.invoke({\"input\": \"What is the capital city of Bangladesh?\"}).content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"tlnCh2LGIos6","executionInfo":{"status":"ok","timestamp":1765507210462,"user_tz":-360,"elapsed":12575,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"7078640b-e63b-42d9-856b-b2b1e8146141"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<bos><start_of_turn>user\\n<start_of_turn>user\\nWhat is the capital city of Bangladesh?\\n<end_of_turn>\\n<start_of_turn>model<end_of_turn>\\n<start_of_turn>model\\nThe capital city of Bangladesh is **Dhaka**. \\n\\nItâ€™s a bustling and historically significant city! ðŸ˜Š\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["Xllm = HuggingFacePipeline.from_model_id(\n","    model_id='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n","    task='text-generation',\n","    pipeline_kwargs=dict(\n","        temperature=0.5,\n","        max_new_tokens=100\n","    )\n",")\n","model2 = ChatHuggingFace(llm=Xllm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3BleCXi6cxUq","executionInfo":{"status":"ok","timestamp":1765508054700,"user_tz":-360,"elapsed":13547,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"c9cff8b8-cbeb-4235-d20e-bcaf0698f6be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n"]}]},{"cell_type":"code","source":["model2.invoke(\"What is the capital city of bangladesh?\").content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"xie8fEBiexTL","executionInfo":{"status":"ok","timestamp":1765508191027,"user_tz":-360,"elapsed":6795,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"3176961b-6f3d-4165-f793-593663a51687"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<|user|>\\nWhat is the capital city of bangladesh?</s>\\n<|assistant|>\\nThe capital city of Bangladesh is Dhaka.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["# Simple Chain"],"metadata":{"id":"DhnfN4FhPQln"}},{"cell_type":"code","source":["simple_prompts = PromptTemplate(\n","    template = \"\"\"\n","      What is the capital city of {country}?\n","    \"\"\",\n","    input_variables = ['country']\n",")"],"metadata":{"id":"7EhYf46UQkPW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["str_parser = StrOutputParser()"],"metadata":{"id":"H_BFubJ8PJHu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["simple_chain = simple_prompts | model | str_parser\n","# simple_result = simple_chain.invoke({\"input\": \"What is the capital city of Bangladesh?\"})\n","simple_result = simple_chain.invoke({\"country\": \"Bangladesh\"})\n","\n","simple_result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"6iLt8jwsPI_c","executionInfo":{"status":"ok","timestamp":1765507268356,"user_tz":-360,"elapsed":7259,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"91b83540-7075-4b5f-f4f3-d3ebc2605072"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<bos><start_of_turn>user\\nWhat is the capital city of Bangladesh?<end_of_turn>\\n<start_of_turn>model\\nThe capital city of Bangladesh is **Dhaka**.\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["# Sequential Chains"],"metadata":{"id":"4YzVGdUYSBts"}},{"cell_type":"code","source":["parser = StrOutputParser()"],"metadata":{"id":"2vcwa6eVTN08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["template1 = PromptTemplate(\n","    template = \"What is the Capital city of {country}?\",\n","    input_variables=['country']\n",")\n","\n","template2 = PromptTemplate(\n","    template = \"Tell me 3 lines of poem for following text \\n{capital}\",\n","    input_variables = ['capital']\n",")"],"metadata":{"id":"-GunktDuMzhX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seq_chain = template1 | model | parser | template2 | model | parser\n","seq_result = seq_chain.invoke({'country': 'bangladesh'})\n","seq_result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"POqvHo55MzeN","executionInfo":{"status":"ok","timestamp":1765507339910,"user_tz":-360,"elapsed":26746,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"a1e73dd4-1ad4-446a-e27c-f99aa8f5f59e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<bos><start_of_turn>user\\nTell me 3 lines of poem for following text \\n<bos><start_of_turn>user\\nWhat is the Capital city of bangladesh?<end_of_turn>\\n<start_of_turn>model\\nThe capital city of Bangladesh is **Dhaka**.<end_of_turn>\\n<start_of_turn>model\\nOkay, here are three lines of poetry inspired by that information:\\n\\nA city of ancient grace,\\nDhaka stands, a vibrant space,\\nWhere history and future embrace.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["seq_result.split('<start_of_turn>')[-1]"],"metadata":{"id":"O6MTGWzyNcD2","executionInfo":{"status":"ok","timestamp":1765507416811,"user_tz":-360,"elapsed":43,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"7e51d676-f920-46d0-d992-1b5a5ec28c39"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'model\\nOkay, here are three lines of poetry inspired by that information:\\n\\nA city of ancient grace,\\nDhaka stands, a vibrant space,\\nWhere history and future embrace.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["# Parallel Chains"],"metadata":{"id":"7EXXcuWvWt0l"}},{"cell_type":"markdown","source":["## Prompt Template Create"],"metadata":{"id":"2_dyGWE8fbHD"}},{"cell_type":"code","source":["# Parallel 1, Make Summary\n","template1 = PromptTemplate(\n","    template = \"lets summary of the following texts \\n{text}\",\n","    input_variables = ['text']\n",")\n","\n","# Parallel 2, Make Question\n","template2 = PromptTemplate(\n","    template = \"lets make 5 short question on following texts \\n{text}\",\n","    input_variables = ['text']\n",")\n","\n","# Merge of Parallel 1 and Parallel 2\n","template3 = PromptTemplate(\n","    template = \"Lets make merge these two answer on this format \\n Answer1: Summary\\n{summary}\\nAnswer2: Questions:\\n{questions}\",\n","    input_variables = ['summary', 'questions']\n",")\n"],"metadata":{"id":"atVOArfzVOI5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Parser"],"metadata":{"id":"d4_HWyQmhLI1"}},{"cell_type":"code","source":["parser = StrOutputParser()"],"metadata":{"id":"qy23WY8iVOFx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Make Parallel Runnable"],"metadata":{"id":"kgxcyiq6hwlD"}},{"cell_type":"code","source":["parallel_chain = RunnableParallel({\n","    'summary': template1 | model | parser,\n","    'questions': template2 | model2 | parser\n","})"],"metadata":{"id":"o4TkwfbLVOCm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Merge Chains"],"metadata":{"id":"UQTaEbDmiXRz"}},{"cell_type":"code","source":["merge_chain = template3 | model | parser"],"metadata":{"id":"JPFusuh8ikd1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Final Chain"],"metadata":{"id":"avqnMICsirmd"}},{"cell_type":"code","source":["final_chain = parallel_chain | merge_chain"],"metadata":{"id":"mI1VudsNiXB7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Invoke Chains"],"metadata":{"id":"CkEV_lsLi15z"}},{"cell_type":"code","source":["with open('data.txt') as f:\n","    text = f.read()"],"metadata":{"id":"G5WG0RFKVN_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text"],"metadata":{"id":"MGPK0oYhVN70","colab":{"base_uri":"https://localhost:8080/","height":157},"executionInfo":{"status":"ok","timestamp":1765509406042,"user_tz":-360,"elapsed":8,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"efef2e3a-f555-4b6a-dfd1-4cccae5e1699"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Integrating Hugging Face models with LangChain allows you to leverage thousands of open-source models for a wide range of tasks, from text generation to embeddings. A dedicated langchain-huggingface package, jointly maintained by both teams, facilitates this integration. \\nMethods of Integration\\nYou can integrate Hugging Face models with LangChain in two primary ways:\\n1. Using the Hugging Face Inference API (Cloud-Hosted)\\nThis method uses the Hugging Face API to run models on serverless infrastructure, requiring an API token. \\nSetup:\\nCreate a free Hugging Face account and get a read-only API token from your profile settings.\\nSet the token as an environment variable: os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_...\".\\nInstall the necessary library: pip install langchain-huggingface'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["final_result = final_chain.invoke({'text': text})\n","final_result"],"metadata":{"id":"wEH1DYFWVN4Y","colab":{"base_uri":"https://localhost:8080/","height":678},"executionInfo":{"status":"ok","timestamp":1765510004297,"user_tz":-360,"elapsed":314708,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"fd986550-c78f-4e30-9f1f-6f39ccac2112"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<bos><start_of_turn>user\\nLets make merge these two answer on this format \\n Answer1: Summary\\n<bos><start_of_turn>user\\nlets summary of the following texts \\nIntegrating Hugging Face models with LangChain allows you to leverage thousands of open-source models for a wide range of tasks, from text generation to embeddings. A dedicated langchain-huggingface package, jointly maintained by both teams, facilitates this integration. \\nMethods of Integration\\nYou can integrate Hugging Face models with LangChain in two primary ways:\\n1. Using the Hugging Face Inference API (Cloud-Hosted)\\nThis method uses the Hugging Face API to run models on serverless infrastructure, requiring an API token. \\nSetup:\\nCreate a free Hugging Face account and get a read-only API token from your profile settings.\\nSet the token as an environment variable: os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_...\".\\nInstall the necessary library: pip install langchain-huggingface<end_of_turn>\\n<start_of_turn>model\\nOkay, here\\'s a summary of the text, broken down into key points:\\n\\n**Core Idea:**  LangChain can use Hugging Face models to perform various tasks (like text generation and embedding) without needing to manage the models themselves.\\n\\n**Key Points:**\\n\\n* **Hugging Face Integration:** LangChain integrates with Hugging Face models.\\n* **Large Model Library:** It provides access to thousands of open-source models.\\n* **Dedicated Package:** A joint effort by teams maintains a dedicated package for this integration.\\n* **Two Integration Methods:**\\n    * **Hugging Face Inference API:**  Run models on serverless infrastructure via the Hugging Face API.  Requires an API token.\\n    * **Manual Setup:**  You need to create a Hugging Face account, obtain an API token, and set it as an environment variable.\\n\\n**In short, it\\'s a way to easily use powerful AI models within the LangChain framework.**\\n\\n\\nAnswer2: Questions:\\n<|user|>\\nlets make 5 short question on following texts \\nIntegrating Hugging Face models with LangChain allows you to leverage thousands of open-source models for a wide range of tasks, from text generation to embeddings. A dedicated langchain-huggingface package, jointly maintained by both teams, facilitates this integration. \\nMethods of Integration\\nYou can integrate Hugging Face models with LangChain in two primary ways:\\n1. Using the Hugging Face Inference API (Cloud-Hosted)\\nThis method uses the Hugging Face API to run models on serverless infrastructure, requiring an API token. \\nSetup:\\nCreate a free Hugging Face account and get a read-only API token from your profile settings.\\nSet the token as an environment variable: os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_...\".\\nInstall the necessary library: pip install langchain-huggingface</s>\\n<|assistant|>\\n1. Using the Hugging Face Inference API (On-Premise)\\nThis method uses the Hugging Face Inference API to run models on on-premise infrastructure, requiring a local installation of the required libraries.\\nSetup:\\nInstall the required libraries: pip install huggingface-inference-api[tensorflow]\\nSet the API token as an environment variable: HF_TOKEN=...\\nInstall the necessary library: pip install<end_of_turn>\\n<start_of_turn>model\\nOkay, here\\'s a summary of the text, formatted as you requested:\\n\\n**Summary:**\\n\\nThe text explains how to integrate Hugging Face models into LangChain. LangChain provides a way to use thousands of open-source models for various tasks, including text generation and embedding.  It achieves this through two main methods:\\n\\n*   **Hugging Face Inference API:**  This method utilizes the Hugging Face Inference API, which runs models on serverless infrastructure and requires an API token.\\n*   **Manual Setup:**  You can manually set up the API token by creating a Hugging Face account, obtaining an API token, and storing it as an environment variable.\\n\\nThe text also provides instructions on how to install the necessary libraries (specifically, `huggingface-inference-api`) for each method.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","source":["# Conditional Chains"],"metadata":{"id":"E7mTo_cMmt2D"}},{"cell_type":"markdown","source":["## Make Base Class"],"metadata":{"id":"bovh9EKynL6_"}},{"cell_type":"code","source":["class Feedback(BaseModel):\n","\n","    sentiment: Literal['positive', 'negative'] = Field(description='Give the sentiment of the feedback')\n"],"metadata":{"id":"jtjHj5yDmgLW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Make Parser"],"metadata":{"id":"Kwi8ihStsF0X"}},{"cell_type":"code","source":["parser = StrOutputParser()\n","pydantic_parser = PydanticOutputParser(pydantic_object=Feedback)"],"metadata":{"id":"JV4IByqInPhd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Make Template"],"metadata":{"id":"msWOZJrgsJMw"}},{"cell_type":"code","source":["pyd_template1 = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are a sentiment classifier. Classify the sentiment of the provided feedback as either 'positive' or 'negative'. Your response MUST be a JSON object with a single key 'sentiment' and its corresponding value. Example output: {{\\\"sentiment\\\": \\\"positive\\\"}}\\n\"),\n","    (\"human\", \"{feedback}\"),\n","])\n","\n","pyd_template1 = prompt1.partial(format_instructions = pydantic_parser.get_format_instructions())"],"metadata":{"id":"A9uhSJ50ndLN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Classifier Chain"],"metadata":{"id":"UpFA59MEsMol"}},{"cell_type":"code","source":["classifier_chain = pyd_template1 | model | pydantic_parser"],"metadata":{"id":"A_2z2ZQO2n03"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result1 = classifier_chain.invoke({'feedback': 'This phone is very bad'})\n","result1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GYCDoPpOnpE5","executionInfo":{"status":"ok","timestamp":1765514387887,"user_tz":-360,"elapsed":13829,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"3b43f796-9f1b-46a3-f308-288cc8298fa4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Feedback(sentiment='negative')"]},"metadata":{},"execution_count":119}]},{"cell_type":"code","source":["type(result1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"8Vaz3DYErx9A","executionInfo":{"status":"ok","timestamp":1765514390893,"user_tz":-360,"elapsed":10,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"1f73c9ff-99b9-4642-b5ff-4a8c4c688c39"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["__main__.Feedback"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>Feedback</b><br/>def __init__(self, /, **data: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\"></a>!!! abstract &quot;Usage Documentation&quot;\n","    [Models](../concepts/models.md)\n","\n","A base class for creating Pydantic models.\n","\n","Attributes:\n","    __class_vars__: The names of the class variables defined on the model.\n","    __private_attributes__: Metadata about the private attributes of the model.\n","    __signature__: The synthesized `__init__` [`Signature`][inspect.Signature] of the model.\n","\n","    __pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n","    __pydantic_core_schema__: The core schema of the model.\n","    __pydantic_custom_init__: Whether the model has a custom `__init__` function.\n","    __pydantic_decorators__: Metadata containing the decorators defined on the model.\n","        This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n","    __pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n","        __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n","    __pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n","    __pydantic_post_init__: The name of the post-init method for the model, if defined.\n","    __pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n","    __pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n","    __pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n","\n","    __pydantic_fields__: A dictionary of field names and their corresponding [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n","    __pydantic_computed_fields__: A dictionary of computed field names and their corresponding [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n","\n","    __pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n","        is set to `&#x27;allow&#x27;`.\n","    __pydantic_fields_set__: The names of fields explicitly set during instantiation.\n","    __pydantic_private__: Values of private attributes set on the model instance.</pre></div>"]},"metadata":{},"execution_count":120}]},{"cell_type":"code","source":["result1.sentiment"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"v1awB8B3rzoS","executionInfo":{"status":"ok","timestamp":1765514394077,"user_tz":-360,"elapsed":64,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"6cc577c0-68fa-4e2a-9fce-cf6785869f78"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'negative'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":121}]},{"cell_type":"markdown","source":["## Prompt2 - Template"],"metadata":{"id":"-NEZYAAIsdXN"}},{"cell_type":"code","source":["template2 = PromptTemplate(\n","    template='Write an appropriate response to this positive feedback \\n {feedback}',\n","    input_variables=['feedback']\n",")"],"metadata":{"id":"yvrd4aczr6CP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prompt3 - Template"],"metadata":{"id":"fc68i_t8shWF"}},{"cell_type":"code","source":["template3 = PromptTemplate(\n","    template='Write an appropriate response to this negative feedback \\n {feedback}',\n","    input_variables=['feedback']\n",")"],"metadata":{"id":"dc0fTBu5siOG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##  Branch Chain"],"metadata":{"id":"sx4f--I_yhw2"}},{"cell_type":"code","source":["branch_chain = RunnableBranch(\n","    # (condition, chain)\n","    # if x == positive\n","    (lambda x: x.sentiment == 'positive', template2 | model | parser),\n","\n","    # else if x == 'negative'\n","    (lambda x: x.sentiment == 'negative', template3 | model | parser),\n","\n","    # else\n","    RunnableLambda(lambda x: \"can not give answer here\")\n",")"],"metadata":{"id":"jB6Lz9Pkupw8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cond_final_chain = classifier_chain | branch_chain\n","\n","cond_result = cond_final_chain.invoke({'feedback': 'This is a good phone'})\n","cond_result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"iDD8-ek2upuT","executionInfo":{"status":"ok","timestamp":1765514444472,"user_tz":-360,"elapsed":38000,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"7239074c-fcf9-4be4-a11b-95885c5504d7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"<bos><start_of_turn>user\\nWrite an appropriate response to this positive feedback \\n sentiment='positive'<end_of_turn>\\n<start_of_turn>model\\nPlease provide the positive feedback youâ€™d like me to respond to! I need the text of the feedback to be able to craft an appropriate response. ðŸ˜Š \\n\\nOnce you paste it in, Iâ€™ll do my best to give you a thoughtful and helpful reply.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":125}]},{"cell_type":"markdown","source":["## Alternative Output Parser"],"metadata":{"id":"VlJ8bbURw70Q"}},{"cell_type":"code","source":["json_parser = JsonOutputParser(\n","    schema={\n","        \"sentiment\": {\"type\": \"string\", \"enum\": [\"positive\", \"negative\"]}\n","    }\n",")\n","\n","prompt_template = PromptTemplate(\n","    template=\"\"\"\n","You are a sentiment classifier.\n","Classify the sentiment of the following feedback:\n","\n","{feedback}\n","\n","Respond **ONLY** in valid JSON. Example:\n","{{\"sentiment\": \"positive\"}}\n","Do NOT include any explanations, extra examples, or markdown.\n","\"\"\",\n","    input_variables=[\"feedback\"]\n",")\n","\n","# Build chain\n","chain = prompt_template | llm | json_parser\n","\n","# Run it\n","feedback_input = \"This phone is very good\"\n","output_json = chain.invoke({\"feedback\": feedback_input})\n","\n","print(output_json)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQeKeMLCuprO","executionInfo":{"status":"ok","timestamp":1765512768345,"user_tz":-360,"elapsed":92756,"user":{"displayName":"Md. Nazmul Hossain","userId":"04609852394000201193"}},"outputId":"46ea45c5-dcbf-4872-d77a-e8949f62d232"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'sentiment': 'positive'}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"EzbuIwXqu0eP"},"execution_count":null,"outputs":[]}]}