{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How implememt code using runnable"
      ],
      "metadata": {
        "id": "m5EcG-GCQTIA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4m2MXnyDKhMI"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod"
      ],
      "metadata": {
        "id": "_1wMYZKLQzaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Custom Runnable Abstract"
      ],
      "metadata": {
        "id": "aaC6UhZPQ-RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Runnable(ABC):\n",
        "\n",
        "  @abstractmethod\n",
        "  def invoke(input_data):\n",
        "    pass"
      ],
      "metadata": {
        "id": "Uv_cm8_OQ-HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Custom LLM Model"
      ],
      "metadata": {
        "id": "yGXMOEhnQZ9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLLMModel(Runnable):\n",
        "  def __init__(self):\n",
        "    print('Custom AI Chat Model Created')\n",
        "\n",
        "  def invoke(self, prompts: str):\n",
        "\n",
        "    answer_list = [\n",
        "        'LangChain provides the engineering platform and open source frameworks',\n",
        "        'Bangladesh is a unitary parliamentary republic based on the Westminster system',\n",
        "        'Gopal Bhar is appointed as a jester in Raja Krishnachandras court in medieval Bengal',\n",
        "        \"Ixora is a genus of vibrant, tropical evergreen shrubs\"\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        'query': prompts,\n",
        "        'content': random.choice(answer_list)\n",
        "    }\n",
        "\n",
        "    def predict(self, prompts: str):\n",
        "      return 'This class is no more. try to use invoke method'"
      ],
      "metadata": {
        "id": "6AIeIhleQXv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Custom Prompt Template"
      ],
      "metadata": {
        "id": "ojp5C0p4QhF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyPromptTemplate:\n",
        "  def __init__(self, template: str, input_variables: list[str]) -> None:\n",
        "    self.template = template\n",
        "    self.input_variables = input_variables\n",
        "\n",
        "  def invoke(self, input_dict: dict):\n",
        "    return self.template.format(**input_dict)\n",
        "\n",
        "  def format(self, input_dict: dict) -> str:\n",
        "    return 'This class is no more. try to use invoke method'"
      ],
      "metadata": {
        "id": "kUuRvwMMQdkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Custom Parser"
      ],
      "metadata": {
        "id": "bRmelJAMQmxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyStrOutputParser:\n",
        "\n",
        "  def invoke(self, result: dict):\n",
        "    return result['content']\n",
        "\n",
        "  def parse(self, input_dict: dict) -> str:\n",
        "    return 'This class is no more. try to use invoke method'"
      ],
      "metadata": {
        "id": "mdwDyM58QkED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Custom LLM Chain"
      ],
      "metadata": {
        "id": "JtKgncGnQso7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLLMChain:\n",
        "  def __init__(self, runnable_list: list) -> None:\n",
        "    self.runnable_list = runnable_list\n",
        "\n",
        "  def invoke(self, input_dict):\n",
        "    input = input_dict\n",
        "\n",
        "    for runnable in self.runnable_list:\n",
        "      input = runnable.invoke(input)\n",
        "\n",
        "    return input\n",
        "\n",
        "  def run(self, input_dict):\n",
        "    return 'This class is no more. try to use invoke method'"
      ],
      "metadata": {
        "id": "0ib5_fI-QoV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Models"
      ],
      "metadata": {
        "id": "jTJQOIE9SqyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyLLMModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kt6vFBGSofE",
        "outputId": "6b1546fb-4916-4911-ffd1-6c457fd9f634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom AI Chat Model Created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = MyPromptTemplate(\n",
        "    template= \"Hello {length} World {topic}\",\n",
        "    input_variables = ['length', 'topic']\n",
        ")"
      ],
      "metadata": {
        "id": "eIu7GsvBSwHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = MyStrOutputParser()"
      ],
      "metadata": {
        "id": "g7vf7ThNSzWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Chain\n",
        "\n",
        "chain = MyLLMChain([\n",
        "    template,\n",
        "    model,\n",
        "    parser\n",
        "])"
      ],
      "metadata": {
        "id": "bkE58p4BS7D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({'length': 10, 'topic': 'AI'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RYW7odRpTHzq",
        "outputId": "1b5980c4-c004-491b-ca8c-cf966bd1525e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bangladesh is a unitary parliamentary republic based on the Westminster system'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel"
      ],
      "metadata": {
        "id": "3ea5IiFQU8mM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template1 = MyPromptTemplate(\n",
        "    template='Write a joke about {topic}',\n",
        "    input_variables=['topic']\n",
        ")\n",
        "\n",
        "template2 = MyPromptTemplate(\n",
        "    template='Explain the following joke {response}',\n",
        "    input_variables=['response']\n",
        ")"
      ],
      "metadata": {
        "id": "GaGL-rlRU9kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = MyLLMModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcDNzLkQVAOd",
        "outputId": "a0bc0856-4a1d-4fbf-8799-c4170f5b8bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom AI Chat Model Created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential Chain"
      ],
      "metadata": {
        "id": "A8HyhFi0Vc8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain1 = MyLLMChain([\n",
        "    template1,\n",
        "    model\n",
        "])\n",
        "\n",
        "chain2 = MyLLMChain([\n",
        "    template2,\n",
        "    model,\n",
        "    parser\n",
        "])"
      ],
      "metadata": {
        "id": "aem1u1VnVKTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Chain"
      ],
      "metadata": {
        "id": "u_E-5nRUVgnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_chain = MyLLMChain([\n",
        "    chain1,\n",
        "    chain2\n",
        "])"
      ],
      "metadata": {
        "id": "G-2E_ystVbBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MapOutputToResponse(Runnable):\n",
        "    def invoke(self, input_data: str):\n",
        "        return {'response': input_data}\n",
        "\n",
        "# Redefine chain1 to output a string using the parser\n",
        "chain1_fixed = MyLLMChain([\n",
        "    template1,\n",
        "    model,\n",
        "    parser\n",
        "])\n",
        "\n",
        "# Recreate final_chain with the fixed chain1 and the mapping runnable\n",
        "final_chain = MyLLMChain([\n",
        "    chain1_fixed,\n",
        "    MapOutputToResponse(),\n",
        "    chain2\n",
        "])\n",
        "\n",
        "final_chain.invoke({'topic': 'xAI'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cW2L1EReVobV",
        "outputId": "5b73eade-c58a-4f38-d964-778f83436790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ixora is a genus of vibrant, tropical evergreen shrubs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_YGKho6Vs8p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}